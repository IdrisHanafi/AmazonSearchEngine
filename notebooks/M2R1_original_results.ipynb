{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aff9218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import random\n",
    "import boto3\n",
    "import random\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import joblib\n",
    "import gzip\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import collections\n",
    "from collections import Counter\n",
    "import re as regex\n",
    "from scipy.sparse import csr_matrix\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import remove_stopwords, STOPWORDS\n",
    "# from gensim import utils\n",
    "from bs4 import BeautifulSoup as BSHTML\n",
    "from gensim.parsing.preprocessing import preprocess_string, STOPWORDS #, remove_stopword_tokens\n",
    "import boto3\n",
    "import logging\n",
    "# from ppring import ppring\n",
    "from botocore.exceptions import ClientError\n",
    "import requests\n",
    "from PIL import Image\n",
    "import sys # to access the system\n",
    "import cv2\n",
    "from IPython.display import Image "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffed740",
   "metadata": {},
   "source": [
    "### M2 LAMBDA DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e74e8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'index/M2_category_index.pickle'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INPUT FILES:\n",
    "\"datasets/M2_tfidf_mtx\"     \n",
    "'models/M2_tfidf.joblib'\n",
    "'index/M2_category_labels.data'\n",
    "'datasets/M2_rank.data'\n",
    "'index/M2_category_index.pickle'\n",
    "\n",
    "# OUTPUT: top 5 category labels and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89fabac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Lambda function: takes a query and returns the top 5 category keys of recommendations\n",
    "INPUT files: \"M2_tfidf_mtx.csv\" , \"M2.joblib\" ,  \"M2_categories.json\" + query\n",
    "OUTPUT: top 5 tuples of matching categoris\n",
    "1- Creates a class tfidf and download dependencies in the first instance, tries to save in cache\n",
    "2- Takes each query and vectorize\n",
    "3- Calculate simirality tuples\n",
    "4- Ranks recommendation based on similarity and np.log(count of asin in each category) '''\n",
    "\n",
    "# match=set(self.M2.get_feature_names_out()) & set(liste)\n",
    "# creating class to import necessary matrices and models for retrival\n",
    "class tfidf:\n",
    "    def __init__(self):\n",
    "        # load cleaned group_by data sets and models from disk\n",
    "        self.mtx=self.load_sparse_csr(\"datasets/M2_tfidf_mtx\")        \n",
    "        self.M2 = joblib.load('models/M2_tfidf.joblib')\n",
    "        self.stemmer = PorterStemmer() \n",
    "        self.quer_R1 = None\n",
    "        self.simi = None\n",
    "        \n",
    "        with open('index/M2R1_big_dico.pickle', 'rb') as filehandle:\n",
    "            self.big_index = pickle.load(filehandle)\n",
    "        \n",
    "        self.tfidf_mtx = self.load_sparse_csr(\"datasets/R1_tfidf_mtx\")\n",
    "        self.model = joblib.load('models/R1_tfidf.joblib')\n",
    "            \n",
    "        with open('datasets/M2_rank.data', 'rb') as filehandle:\n",
    "            self.rank = np.array(pickle.load(filehandle))\n",
    "            \n",
    "        with open('index/M2_category_index.pickle', 'rb') as filehandle:\n",
    "            self.category_index = pickle.load(filehandle)\n",
    "            \n",
    "        with open('index/M2R1_asin_category.pickle', 'rb') as filehandle:\n",
    "            self.asin_category = pickle.load(filehandle)\n",
    "\n",
    "            \n",
    "    def load_sparse_csr(self, filename):\n",
    "        # here we need to add .npz extension manually\n",
    "        loader = np.load(filename + '.npz')\n",
    "        return csr_matrix((loader['data'], loader['indices'], loader['indptr']),\n",
    "                      shape=loader['shape']) \n",
    "    \n",
    "    def asin_of_categories(self,cat_idx):\n",
    "        \n",
    "        info = self.big_index[cat_idx]\n",
    "        cat = info[0]\n",
    "        start = info[1]\n",
    "        finish = info[2]\n",
    "\n",
    "        self.simi = cosine_similarity(self.tfidf_mtx,self.quer_R1)\n",
    "        simi_mtx = self.simi[start:finish,]\n",
    "            \n",
    "        arr2 = np.argsort(-simi_mtx,axis=0)[:5] + start\n",
    "        dim = arr2.shape[0]\n",
    "        idx_asin = list(arr2.reshape(dim,)) \n",
    "        \n",
    "        return idx_asin\n",
    "        \n",
    "        \n",
    "    \n",
    "    ## retrieve match tfidf (LAMBDA FUNCTION)\n",
    "    def M2_query_to_category_function(self,q):\n",
    "        stop_words= set(stopwords.words('english'))\n",
    "        liste=[self.stemmer.stem(w) for w in word_tokenize(q) if not w.lower() in stop_words]\n",
    "        n_valid_words= len([x for x in liste if len(x)>2])\n",
    "        string=' '.join(element for element in liste)       \n",
    "        quer = self.M2.transform([string])\n",
    "        self.quer_R1 = self.model.transform([string])\n",
    "        \n",
    "        simi = cosine_similarity(self.mtx,quer) \n",
    "        \n",
    "        Beta_factor = 0.0\n",
    "        simi_mtx = simi + self.rank * Beta_factor # rank is a coeff that you can tweak np.log(gb[\"count\"] + 1) * 0.35\n",
    "        \n",
    "        # results = list(self.category[np.argsort(-simi_mtx,axis=0)[:5].reshape(5,)])\n",
    "        idx= list(np.argsort(-simi_mtx,axis=0)[:5].reshape(5,))\n",
    "        \n",
    "        liste = []\n",
    "        for element in idx:\n",
    "            ##### M2 returns indices\n",
    "            retour = self.asin_of_categories(element)\n",
    "            liste = liste + retour\n",
    "        \n",
    "        return idx, np.round(np.max(simi),2), n_valid_words, liste\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5022c5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# take as input the 1000 query test data frame and returns the metrics in an array\n",
    "def testing_queries(min_query,max_query, query_test,threshold_list): \n",
    "    # calling the class\n",
    "    ob = tfidf() \n",
    "    spread = max_query-min_query\n",
    "    arr = np.zeros((spread * len(threshold_list)*2, 13))\n",
    "    for n_words in range(0,spread):    \n",
    "        valid = 0\n",
    "        col = \"query_{}\".format(n_words + min_query)\n",
    "        queries = list(zip(query_test[col], query_test.cat_idx, query_test.label, query_test.asin))\n",
    "\n",
    "        for element in queries:\n",
    "\n",
    "            q = element[0]\n",
    "            cat_idx = element[1]\n",
    "            label = element[2]\n",
    "            asin_idx = element[3]\n",
    "\n",
    "            liste_idx, first_maxi, n_valid_words, liste_asin_first = ob.M2_query_to_category_function(q)\n",
    "            valid += n_valid_words\n",
    "\n",
    "            # for matches in range(1,len(idx)):\n",
    "            first = liste_idx #[:matches]\n",
    "            first_match = len(set(first) & set([cat_idx]))\n",
    "\n",
    "            matches_asin = len(set([asin_idx]) & set(liste_asin_first))\n",
    "\n",
    "            for top_n in range(0,2):\n",
    "                if top_n == 1:\n",
    "                    first = liste_idx[:3]\n",
    "                    first_match = len(set(first) & set([cat_idx]))\n",
    "                    \n",
    "                for j, threshold in enumerate(threshold_list):\n",
    "                    indice = j + n_words * len(threshold_list) + top_n * (spread * len(threshold_list))\n",
    "                    # if label == 1\n",
    "                    if label:\n",
    "                        if (first_maxi > threshold and first_match) :\n",
    "                            # counting TP and matches\n",
    "                            arr[indice,0] += 1\n",
    "                            arr[indice,1] += 1\n",
    "                            ### at asin level\n",
    "                            arr[indice,9] += matches_asin\n",
    "                        else:\n",
    "                            # counting FN\n",
    "                            arr[indice,3] += 1\n",
    "                            arr[indice,10] += 1\n",
    "                    # if label == 0\n",
    "                    else:\n",
    "                        # counting FP and matches\n",
    "                        if (first_maxi > threshold):\n",
    "                            arr[indice,0] += 1\n",
    "                            arr[indice,2] += 1\n",
    "                            arr[indice,11] += 1\n",
    "                        # counting TN \n",
    "                        else:\n",
    "                            arr[indice,4] += first_match\n",
    "                            arr[indice,12] += 1\n",
    "                    # counting real stem words\n",
    "                    arr[indice,5] = np.round(valid / len(queries),2)\n",
    "                    arr[indice,6] = threshold\n",
    "                    arr[indice,7] = n_words + min_query\n",
    "                    arr[indice,8] = len(first)\n",
    "    return arr\n",
    "\n",
    "# takes the array of metrics and returns the formated data frame with all the metrics and the merged\n",
    "def formating_array(arr, filename, longueur):  \n",
    "    col=[\"match\",\"TP\",\"FP\",\"FN\",\"TN\",\"stem_words\",\"threshold\",\"n_words\",\"TOP_N\",\"TP_asin\",\"FN_asin\", \"FP_asin\",\"TN_asin\"]  \n",
    "    df = pd.DataFrame(arr, columns = col)\n",
    "    df[\"queries\"] = longueur\n",
    "    df[\"TN\"] = longueur - (df[\"TP\"] + df[\"FP\"] + df[\"FN\"])\n",
    "    df= df [['n_words','stem_words',\"threshold\",\"TOP_N\",'queries','match', 'TP','FP', 'FN', 'TN',\"TP_asin\",\"FN_asin\", \"FP_asin\",\"TN_asin\"]]\n",
    "    df[\"accuracy\"] = np.round((df[\"TP\"] + df[\"TN\"]) / longueur, 2) # check\n",
    "    df[\"Precision\"] = np.round(df[\"TP\"]/ (df[\"TP\"] + df[\"FP\"]),2) # check\n",
    "    df[\"Recall\"] = np.round(df[\"TP\"]/ (df[\"TP\"] + df[\"FN\"]), 2) #check\n",
    "\n",
    "    df[\"FN_asin\"] = df[\"FN_asin\"] + df[\"TP_asin\"] - df[\"TP_asin\"]\n",
    "    df[\"accuracy_asin\"] = np.round((df[\"TP_asin\"] + df[\"TN_asin\"]) / longueur, 2) # check\n",
    "    df[\"Precision_asin\"] = np.round(df[\"TP_asin\"]/ (df[\"TP_asin\"] + df[\"FP_asin\"]),2) # check\n",
    "    df[\"Recall_asin\"] = np.round(df[\"TP_asin\"]/ (df[\"TP_asin\"] + df[\"FN_asin\"]), 2) \n",
    "    df[\"F1\"] = np.round((2 * df[\"Precision\"] * df[\"Recall\"]) / (df[\"Precision\"] + df[\"Recall\"]),2)\n",
    "    df[\"F1_asin\"] = np.round((2 * df[\"Precision_asin\"] * df[\"Recall_asin\"]) / (df[\"Precision_asin\"] + df[\"Recall_asin\"]),2)\n",
    "    \n",
    "    # export to csv file\n",
    "    df1 = df.reset_index()\n",
    "    df1 = df1[[\"index\",\"threshold\",\"accuracy\",\"Precision\",\"Recall\",\"F1\",\"F1_asin\"]]\n",
    "    df1.columns = [\"idx\",\"threshold\",\"accuracy\",\"Precision\",\"Recall\",\"F1\",\"F1_asin\"]\n",
    "    df.to_csv(filename, index=False)\n",
    "    \n",
    "    return df \n",
    "\n",
    "# Takes a data frame and returns \n",
    "def top_results(metrics,data):\n",
    "    df1 = data.reset_index()\n",
    "    df1 = df1[[\"index\",\"threshold\",\"accuracy\",\"Precision\",\"Recall\",\"F1\",\"Precision_asin\",\"F1_asin\"]]\n",
    "    df1.columns = [\"idx\",\"threshold\",\"accuracy\",\"Precision\",\"Recall\",\"F1\",\"Precision_asin\",\"F1_asin\"]\n",
    "    \n",
    "    col = metrics\n",
    "    machin = data.groupby(['n_words','TOP_N'])[col].nlargest(1).reset_index()\n",
    "    del machin[col]\n",
    "    machin.columns = [\"n_words\",\"top_n\",\"idx\"]\n",
    "    df_merge = machin.merge(df1, on = \"idx\", suffixes=(False, False))\n",
    "    df_merge[\"n_words\"] = df_merge[\"n_words\"].astype(int)\n",
    "    df_merge[\"top_n\"] = df_merge[\"top_n\"].astype(int)\n",
    "    del df_merge[\"idx\"]\n",
    "    \n",
    "    return df_merge\n",
    "\n",
    "\n",
    "def initialize():\n",
    "    # range of length of query words to test [start, finish[ \n",
    "    min_query = 3\n",
    "    max_query = 8\n",
    "\n",
    "    ############# KEEP TRUE AS DEFAULT ##############\n",
    "    download = True\n",
    "    ############################################\n",
    "    \n",
    "    # will dowload the filename results\n",
    "    if download:\n",
    "        filename = \"results/M2R1_full_original_results.csv\" \n",
    "        df_results = pd.read_csv(filename)  \n",
    "    \n",
    "    # re-runs everything based on importing the query_test dataset\n",
    "    if not download:       \n",
    "        query_test = pd.read_csv(\"datasets/query_test_1000.csv\") \n",
    "        # Setting the similarity threshold range\n",
    "        threshold_list = [x/100 for x in range(0,101)]\n",
    "        # threshold_list = [0.30,0.45,0.50]\n",
    "        # query_test = query_test.sample(100)\n",
    "        ## returns the array with all the metrics, longuest query\n",
    "        arr = testing_queries(min_query,max_query, query_test,threshold_list)\n",
    "        longueur = len(query_test)\n",
    "        df_results = formating_array(arr, filename, longueur)  \n",
    "        filename1 = \"results/M2R1_full_original_results.csv\"\n",
    "        df_results.to_csv(filename1, index = False)\n",
    "\n",
    "    ### ANALYSIS FIELD\n",
    "    # returning top results for a specific metrics\n",
    "    metrics = \"F1\"\n",
    "    summary_results = top_results(metrics, df_results)\n",
    "    filename2 = \"results/M2R1_original_summary_results.csv\"\n",
    "    summary_results.to_csv(filename2, index = False)\n",
    "    \n",
    "    return df_results, summary_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7282d64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "df_results, summary_results = initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48cb743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6249c9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_words</th>\n",
       "      <th>top_n</th>\n",
       "      <th>threshold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision_asin</th>\n",
       "      <th>F1_asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_words  top_n  threshold  accuracy  Precision  Recall    F1  \\\n",
       "0        3      3       0.00      0.29       0.19    0.13  0.15   \n",
       "1        3      5       0.00      0.31       0.24    0.17  0.20   \n",
       "2        4      3       0.00      0.27       0.20    0.16  0.18   \n",
       "3        4      5       0.21      0.32       0.25    0.19  0.22   \n",
       "4        5      3       0.24      0.32       0.25    0.19  0.22   \n",
       "5        5      5       0.18      0.27       0.26    0.24  0.25   \n",
       "6        6      3       0.22      0.29       0.25    0.21  0.23   \n",
       "7        6      5       0.22      0.31       0.28    0.24  0.26   \n",
       "8        7      3       0.22      0.30       0.26    0.22  0.24   \n",
       "9        7      5       0.23      0.32       0.29    0.25  0.27   \n",
       "\n",
       "   Precision_asin  F1_asin  \n",
       "0            0.11     0.09  \n",
       "1            0.15     0.13  \n",
       "2            0.15     0.13  \n",
       "3            0.20     0.17  \n",
       "4            0.21     0.18  \n",
       "5            0.21     0.20  \n",
       "6            0.22     0.20  \n",
       "7            0.25     0.23  \n",
       "8            0.25     0.23  \n",
       "9            0.28     0.25  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35693e44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
